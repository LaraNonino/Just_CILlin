{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Sg4bOmBSf3f"
   },
   "source": [
    "# Sentiment Classification Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from -r reqs.txt (line 1)) (1.22.4)\n",
      "Requirement already satisfied: torch in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from -r reqs.txt (line 2)) (1.11.0+cu113)\n",
      "Requirement already satisfied: torchvision in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from -r reqs.txt (line 3)) (0.12.0+cu113)\n",
      "Requirement already satisfied: torchtext in /cluster/home/amohame/.local/lib/python3.10/site-packages (from -r reqs.txt (line 4)) (0.12.0)\n",
      "Requirement already satisfied: torchmetrics in /cluster/home/amohame/.local/lib/python3.10/site-packages (from -r reqs.txt (line 5)) (0.11.4)\n",
      "Requirement already satisfied: pytorch_lightning in /cluster/home/amohame/.local/lib/python3.10/site-packages (from -r reqs.txt (line 6)) (2.0.4)\n",
      "Requirement already satisfied: scikit-learn in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from -r reqs.txt (line 7)) (1.1.1)\n",
      "Requirement already satisfied: scipy in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from -r reqs.txt (line 8)) (1.8.1)\n",
      "Requirement already satisfied: nltk in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from -r reqs.txt (line 9)) (3.7)\n",
      "Requirement already satisfied: gensim in /cluster/home/amohame/.local/lib/python3.10/site-packages (from -r reqs.txt (line 10)) (4.3.1)\n",
      "Requirement already satisfied: wandb in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from -r reqs.txt (line 11)) (0.12.17)\n",
      "Requirement already satisfied: typing-extensions in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from torch->-r reqs.txt (line 2)) (4.2.0)\n",
      "Requirement already satisfied: requests in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from torchvision->-r reqs.txt (line 3)) (2.28.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from torchvision->-r reqs.txt (line 3)) (9.1.1)\n",
      "Requirement already satisfied: tqdm in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from torchtext->-r reqs.txt (line 4)) (4.64.0)\n",
      "Requirement already satisfied: packaging in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from torchmetrics->-r reqs.txt (line 5)) (21.3)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from pytorch_lightning->-r reqs.txt (line 6)) (6.0)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from pytorch_lightning->-r reqs.txt (line 6)) (2022.5.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.7.0 in /cluster/home/amohame/.local/lib/python3.10/site-packages (from pytorch_lightning->-r reqs.txt (line 6)) (0.8.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from scikit-learn->-r reqs.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from scikit-learn->-r reqs.txt (line 7)) (3.1.0)\n",
      "Requirement already satisfied: click in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from nltk->-r reqs.txt (line 9)) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from nltk->-r reqs.txt (line 9)) (2022.4.24)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from gensim->-r reqs.txt (line 10)) (6.0.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from wandb->-r reqs.txt (line 11)) (3.1.27)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from wandb->-r reqs.txt (line 11)) (2.8.2)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from wandb->-r reqs.txt (line 11)) (2.3)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from wandb->-r reqs.txt (line 11)) (1.0.9)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from wandb->-r reqs.txt (line 11)) (5.9.5)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from wandb->-r reqs.txt (line 11)) (1.5.12)\n",
      "Requirement already satisfied: six>=1.13.0 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from wandb->-r reqs.txt (line 11)) (1.16.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from wandb->-r reqs.txt (line 11)) (0.4.0)\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from wandb->-r reqs.txt (line 11)) (3.19.4)\n",
      "Requirement already satisfied: pathtools in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from wandb->-r reqs.txt (line 11)) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from wandb->-r reqs.txt (line 11)) (1.2.3)\n",
      "Requirement already satisfied: setuptools in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from wandb->-r reqs.txt (line 11)) (58.1.0)\n",
      "Requirement already satisfied: aiohttp in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch_lightning->-r reqs.txt (line 6)) (3.8.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from GitPython>=1.0.0->wandb->-r reqs.txt (line 11)) (4.0.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from packaging->torchmetrics->-r reqs.txt (line 5)) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from requests->torchvision->-r reqs.txt (line 3)) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from requests->torchvision->-r reqs.txt (line 3)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from requests->torchvision->-r reqs.txt (line 3)) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from requests->torchvision->-r reqs.txt (line 3)) (2022.5.18.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb->-r reqs.txt (line 11)) (5.0.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch_lightning->-r reqs.txt (line 6)) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch_lightning->-r reqs.txt (line 6)) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch_lightning->-r reqs.txt (line 6)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch_lightning->-r reqs.txt (line 6)) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch_lightning->-r reqs.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch_lightning->-r reqs.txt (line 6)) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r reqs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 20:56:46.052564: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "# import pytorch_lightning as L\n",
    "# from pytorch_lightning.loggers import WandbLogger\n",
    "# from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from dataset.twitter_dataset import TwitterDataModule\n",
    "# from recipes.sentiment_analysis import SentimentAnalysisNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 20:07:18.791882: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "embedding_dim = 300\n",
    "    \n",
    "from string import punctuation \n",
    "from preprocessing.embeddings import create_w2v_embeddings\n",
    "\n",
    "translator = str.maketrans('','', punctuation)\n",
    "dm = TwitterDataModule(\n",
    "    \"twitter-datasets/train_pos_full.txt\",\n",
    "    \"twitter-datasets/train_neg_full.txt\",\n",
    "    \"twitter-datasets/test_data.txt\",\n",
    "    convert_to_features=create_w2v_embeddings,\n",
    "    convert_to_features_kwargs={\n",
    "        \"workers\": 8,\n",
    "        \"vector_size\": embedding_dim,\n",
    "        \"min_count\": 1,\n",
    "        \"window\": 5,\n",
    "        \"sample\": 1e-3,\n",
    "    },\n",
    "    tokenizer=lambda x: [tweet.translate(translator).split() for tweet in x],\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1250000it [00:00, 1488044.29it/s]\n",
      "1250000it [00:00, 1918501.17it/s]\n"
     ]
    }
   ],
   "source": [
    "dm.setup(stage=\"fit\")\n",
    "print(dm.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RNNClassifier\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m RNNClassifier(\n\u001b[0;32m----> 4\u001b[0m     rnn\u001b[38;5;241m=\u001b[39m\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mLSTM(\n\u001b[1;32m      5\u001b[0m         input_size\u001b[38;5;241m=\u001b[39mdm\u001b[38;5;241m.\u001b[39mdims[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      6\u001b[0m         hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m      7\u001b[0m         num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      8\u001b[0m         batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m         dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m     10\u001b[0m     ),\n\u001b[1;32m     11\u001b[0m     classifier\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m     12\u001b[0m         nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m16\u001b[39m),\n\u001b[1;32m     13\u001b[0m         nn\u001b[38;5;241m.\u001b[39mBatchNorm1d(\u001b[38;5;241m16\u001b[39m),\n\u001b[1;32m     14\u001b[0m         nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m     15\u001b[0m         nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m8\u001b[39m),\n\u001b[1;32m     16\u001b[0m         nn\u001b[38;5;241m.\u001b[39mBatchNorm1d(\u001b[38;5;241m8\u001b[39m),\n\u001b[1;32m     17\u001b[0m         nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m     18\u001b[0m         nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     19\u001b[0m         nn\u001b[38;5;241m.\u001b[39mSigmoid(),\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     21\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "from models.rnn import RNNClassifier\n",
    "\n",
    "model = RNNClassifier(\n",
    "    rnn=nn.LSTM(\n",
    "        input_size=dm.dims[-1],\n",
    "        hidden_size=64,\n",
    "        num_layers=2,\n",
    "        batch_first=True,\n",
    "        dropout=0.1,\n",
    "    ),\n",
    "    classifier=nn.Sequential(\n",
    "        nn.Linear(64, 16),\n",
    "        nn.BatchNorm1d(16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(16, 8),\n",
    "        nn.BatchNorm1d(8),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(8, 1),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SentimentAnalysisNet(\n",
    "    model,\n",
    "    lr=10e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb_logger = WandbLogger(project=\"cil\")\n",
    "# lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "# checkpoint_callback = ModelCheckpoint(\n",
    "#     monitor='valid/loss',\n",
    "#     dirpath='wandb/ckp',\n",
    "#     filename='models-{epoch:02d}-{valid_loss:.2f}',\n",
    "#     save_top_k=3,\n",
    "#     mode='min'\n",
    "# )\n",
    "# trainer_params = {\"callbacks\": [lr_monitor, checkpoint_callback]}\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=5,\n",
    "    #     # callbacks=trainer_params[\"callbacks\"],\n",
    "    #     # logger=wandb_logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | model     | RNNClassifier  | 102 K \n",
      "1 | criterion | BCELoss        | 0     \n",
      "2 | accuracy  | BinaryAccuracy | 0     \n",
      "---------------------------------------------\n",
      "102 K     Trainable params\n",
      "0         Non-trainable params\n",
      "102 K     Total params\n",
      "0.410     Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f78ffe4391425993841f103883d9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "print(\"start training...\")\n",
    "trainer.fit(model=net, datamodule=dm)\n",
    "print(\"done!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
